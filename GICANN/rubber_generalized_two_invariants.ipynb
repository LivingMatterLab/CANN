{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se438kR0HIri"
      },
      "source": [
        "# Automated Model Discovery for Rubber\n",
        "\n",
        "Model Discovery Papers:\n",
        "1. Invariant-based: https://www.sciencedirect.com/science/article/pii/S1742706123000661\n",
        "2. Principal-stretch-based: https://www.sciencedirect.com/science/article/pii/S2666522023000047\n",
        "\n",
        "Rubber Data Reference: https://pubs.rsc.org/en/content/articlelanding/1944/tf/tf9444000059\n",
        "\n",
        "Code by Denisa Martonov√° Last edited August 2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc5wZXS329As"
      },
      "source": [
        "\n",
        "### 0. Load python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ODWLtwLAQQD"
      },
      "outputs": [],
      "source": [
        "# matplotlib 3.7 and above removed key plotting features used in this notebook; tensorflow is starting to move some aspects to legacy in 2.13.0 but it will run still\n",
        "!pip install matplotlib==3.2.2\n",
        "!pip install tensorflow==2.12.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koxfCXBQn_9g",
        "outputId": "e6bb3695-6883-439b-d836-c2b4823fdfe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numpy: 1.23.5\n",
            "Matplotlib: 3.2.2\n",
            "Tensorflow: 2.12.0\n"
          ]
        }
      ],
      "source": [
        "# import necessary python packages\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import copy\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "# Check Versions\n",
        "print('Numpy: ' + np.__version__)\n",
        "print('Matplotlib: ' + matplotlib.__version__) # must be 3.2.2\n",
        "print('Tensorflow: ' + tf.__version__)\n",
        "#print('Keras: ' + keras.__version__) # comment out if using tf 2.13.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGsjGLS7zi5A",
        "outputId": "77e39845-1c4c-46ac-cc60-913f0ca8f864"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Import excel file, change to match where you saved the file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/CANN_Stanford/generalized_invariants/' # change to where you download this; must be in Google Drive\n",
        "dfs = pd.read_excel(path + 'input/CANNsRUBBERdata.xlsx', sheet_name='Sheet1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuvDD-UW3UIa"
      },
      "source": [
        "### 1. Load Rubber data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6IYNvlxqvQQ"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "def getStressStrain(Region):\n",
        "    if Region =='rubber':\n",
        "        if Region =='rubber':\n",
        "            lam1_bi= dfs.iloc[4:18,3].dropna().astype(np.float64).values\n",
        "            T1_bi = dfs.iloc[4:18,5].dropna().astype(np.float64).values*lam1_bi\n",
        "\n",
        "            #exclude pure shear for training\n",
        "            lam1_ps= tf.ones_like(lam1_bi)\n",
        "            T1_ps = tf.zeros_like(lam1_bi)\n",
        "\n",
        "            lam_uni = dfs.iloc[4:18,0].dropna().astype(np.float64).values\n",
        "            T1_uni = dfs.iloc[4:18,2].dropna().astype(np.float64).values*lam_uni\n",
        "    return lam1_bi,T1_bi,lam1_ps,T1_ps, lam_uni, T1_uni\n",
        "\n",
        "# Define different loading protocols\n",
        "def traindata(modelFit_mode):\n",
        "    if modelFit_mode == 'bi':\n",
        "        model_given = model_bi\n",
        "        input_train = [lam1,lam2]\n",
        "        output_train = [T1_bi,T2_bi]\n",
        "        sample_weights = np.array([1.0] * lam1.shape[0])\n",
        "\n",
        "\n",
        "    elif modelFit_mode == \"uni\":\n",
        "        model_given = model_uni\n",
        "        input_train = lam_uni\n",
        "        output_train = T1_uni\n",
        "        sample_weights = np.array([1.0]*input_train.shape[0])\n",
        "\n",
        "    elif modelFit_mode == \"combi\":\n",
        "        model_given = model_combi\n",
        "        input_train = [lam1_bi,lam1_ps,lam_uni]\n",
        "        output_train = [T1_bi,T1_ps,T1_uni]\n",
        "\n",
        "    return model_given, input_train, output_train\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdsxsk3V1cZp"
      },
      "source": [
        "### L1 and L2 regularization with penalty weight\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDqcHT6r1a8J"
      },
      "outputs": [],
      "source": [
        "def regularize(reg, pen):\n",
        "    if reg == 'L2':\n",
        "        return keras.regularizers.l2(pen)\n",
        "    if reg == 'L1':\n",
        "        return keras.regularizers.l1(pen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YJz85Qq1rVu"
      },
      "source": [
        "## 2a. Strain Energy Model - Invariant-based\n",
        "\n",
        "\n",
        "Next, we define the strain energy function for our isotropic, perfectly incompressible Constitutive Artificial Neural Network with two hidden layers and four and twelve nodes using the invariants of the right Cauchy Green tensor. The first layer generates powers $(\\circ)^1$ and $(\\circ)^2$ of the network inputs,\n",
        "$[I_1-3]$ and $[I_2-3]$, and the second layer applies the identity, $(\\circ)$, the exponential function, $(\\rm{exp}((\\circ))-1)$, and the natural logarithm, $(-\\rm{ln}(1-(\\circ)))$, to these powers.\n",
        "The set of equations for this networks takes the following explicit form,\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{array}{l@{\\hspace*{0.1cm}}c@{\\hspace*{0.1cm}}\n",
        "              l@{\\hspace*{.02cm}}l@{\\hspace*{0.1cm}}\n",
        "              l@{\\hspace*{0.1cm}}c@{\\hspace*{0.1cm}}\n",
        "              l@{\\hspace*{0.1cm}}l@{\\hspace*{0.1cm}}l@{\\hspace*{0.04cm}}\n",
        "              l@{\\hspace*{0.1cm}}c@{\\hspace*{0.1cm}}\n",
        "              l@{\\hspace*{0.1cm}}l@{\\hspace*{0.1cm}}l@{\\hspace*{0.0cm}}\n",
        "              l@{\\hspace*{0.1cm}}l@{\\hspace*{0.1cm}}c@{\\hspace*{0.1cm}}\n",
        "              l@{\\hspace*{0.1cm}}l@{\\hspace*{0.1cm}}l@{\\hspace*{0.0cm}}l}\n",
        "    \\psi(I_1,I_2)\n",
        "&=& w_{2,1}&w_{1,1} &[\\,I_1 - 3\\,]\n",
        "&+& w_{2,2} & [ \\, \\exp (\\,     w_{1,2} & [\\, I_1 -3 \\,]&)   - 1\\,]\n",
        "&-& w_{2,3} &      \\ln (\\, 1 -  w_{1,3} & [\\, I_1 -3 \\,]&) \\\\\n",
        "&+& w_{2,4}&w_{1,4} &[\\,I_1 - 3\\,]^2\n",
        "&+& w_{2,5} & [ \\, \\exp (\\,     w_{1,5} & [\\, I_1 -3 \\,]^2&) - 1\\,]\n",
        "&-& w_{2,6} &      \\ln (\\, 1 -  w_{1,6} & [\\, I_1 -3 \\,]^2&) \\\\\n",
        "&+& w_{2,7}&w_{1,7} &[\\,I_2 - 3\\,]\n",
        "&+& w_{2,8} & [ \\, \\exp (\\,     w_{1,8} & [\\, I_2 -3 \\,]&)   - 1\\,]\n",
        "&-& w_{2,9} &      \\ln (\\, 1 -  w_{1,9} & [\\, I_2 -3 \\,]&)\\\\\n",
        "&+& w_{2,10}&w_{1,10} &[\\,I_2 - 3\\,]^2\n",
        "&+& w_{2,11} & [ \\, \\exp (\\,    w_{1,11} & [\\, I_2 -3 \\,]^2&)- 1\\,]\n",
        "&-& w_{2,12} &      \\ln (\\, 1 - w_{1,12} & [\\, I_2 -3 \\,]^2&) \\,.\n",
        "\\end{array}\n",
        "$$\n",
        "\n",
        "\n",
        "First we define the activation functions and a single Invariant block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jbyl-Tt2vJt"
      },
      "outputs": [],
      "source": [
        "initializer_exp = tf.keras.initializers.RandomUniform(minval=0., maxval=0.1, seed=np.random.randint(0,10000)) # use random integer as seed\n",
        "initializer_1 = 'glorot_normal'\n",
        "\n",
        "# Self defined activation functions for exp term\n",
        "def activation_Exp(x):\n",
        "    return 1.0*(tf.math.exp(x) -1.0)\n",
        "# Self defined activation functions for ln term\n",
        "def activation_ln(x):\n",
        "    return -1.0*tf.math.log(1.0 - (x))\n",
        "\n",
        "# Define network block\n",
        "## kernel is weight\n",
        "def SingleInvNet(I1_ref, idi, reg, pen):\n",
        "    # input: invariant\n",
        "    I_1_w11 = keras.layers.Dense(1,kernel_initializer=initializer_1,kernel_constraint=keras.constraints.NonNeg(),\n",
        "                                 kernel_regularizer=regularize(reg, pen),\n",
        "                                 use_bias=False, activation=None,name='w'+str(1+idi)+'1')(I1_ref) # no activation, correspont to the top ptahway in graph\n",
        "    I_1_w21 = keras.layers.Dense(1,kernel_initializer=initializer_exp,kernel_constraint=keras.constraints.NonNeg(),\n",
        "                                 kernel_regularizer=regularize(reg, pen),\n",
        "                                 use_bias=False, activation=activation_Exp,name='w'+str(2+idi)+'1')(I1_ref) # exp activation, 2nd line in graph\n",
        "\n",
        "    I_1_w31 = keras.layers.Dense(1,kernel_initializer=initializer_1,kernel_constraint=keras.constraints.NonNeg(),\n",
        "                                 kernel_regularizer=regularize(reg, pen),\n",
        "                              use_bias=False, activation=activation_ln,name='w'+str(3+idi)+'1')(I1_ref) # ln activation\n",
        "\n",
        "    # # # input: invariant^2\n",
        "    # I_1_w41 = keras.layers.Dense(1,kernel_initializer=initializer_1,kernel_constraint=keras.constraints.NonNeg(),\n",
        "    #                              kernel_regularizer=regularize(reg, pen),\n",
        "    #                              use_bias=False, activation=None,name='w'+str(4+idi)+'1')(tf.math.square(I1_ref)) # no activation\n",
        "    # I_1_w51 = keras.layers.Dense(1,kernel_initializer=initializer_exp,kernel_constraint=keras.constraints.NonNeg(),\n",
        "    #                              kernel_regularizer=regularize(reg, pen),\n",
        "    #                              use_bias=False, activation=activation_Exp,name='w'+str(5+idi)+'1')(tf.math.square(I1_ref)) # exp activation\n",
        "    # I_1_w61 = keras.layers.Dense(1,kernel_initializer=initializer_1,kernel_constraint=keras.constraints.NonNeg(),\n",
        "    #                              kernel_regularizer=regularize(reg, pen),\n",
        "    #                           use_bias=False, activation=activation_ln,name='w'+str(6+idi)+'1')(tf.math.square(I1_ref)) # ln activation\n",
        "\n",
        "    collect = [I_1_w11, I_1_w21,I_1_w31]\n",
        "    collect_out = tf.keras.layers.concatenate(collect, axis=1)\n",
        "\n",
        "    return collect_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjNgzkY63fQ7"
      },
      "source": [
        "Then we define the strain energy keras submodel as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wDqgN2F1m4l"
      },
      "outputs": [],
      "source": [
        "def StrainEnergyCANN_invariant(reg, pen):\n",
        "\n",
        "    # Inputs defined\n",
        "    I1_in = tf.keras.Input(shape=(1,), name='I1')\n",
        "    I2_in = tf.keras.Input(shape=(1,), name='I2')\n",
        "\n",
        "\n",
        "    # Put invariants in the reference configuration (substrct 3)\n",
        "    I1_ref = keras.layers.Lambda(lambda x: (x-3.0))(I1_in)\n",
        "    I2_ref = keras.layers.Lambda(lambda x: (x-3.0))(I2_in)\n",
        "\n",
        "    I1_out = SingleInvNet(I1_ref, 0, reg, pen)\n",
        "    terms = I1_out.get_shape().as_list()[1] # 6 terms per invariant\n",
        "    I2_out = SingleInvNet(I2_ref, terms, reg, pen)\n",
        "\n",
        "    ALL_I_out = [I1_out,I2_out]\n",
        "    # ALL_I_out = [I1_out]\n",
        "    ALL_I_out = tf.keras.layers.concatenate(ALL_I_out,axis=1)\n",
        "\n",
        "    # second layer\n",
        "    ## get 2nd col of weights\n",
        "    W_ANN = keras.layers.Dense(1,kernel_initializer='glorot_normal',kernel_constraint=keras.constraints.NonNeg(),\n",
        "                               kernel_regularizer=regularize(reg, pen),\n",
        "                           use_bias=False, activation=None,name='wx2')(ALL_I_out)\n",
        "    Psi_model = keras.models.Model(inputs=[I1_in, I2_in], outputs=[W_ANN], name='Psi')\n",
        "    # Psi_model = keras.models.Model(inputs=[I1_in], outputs=[W_ANN], name='Psi')\n",
        "\n",
        "\n",
        "    return Psi_model, terms*2  # 12 terms\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm8k_7Ve3yAb"
      },
      "source": [
        "### 3. Stress Models\n",
        "\n",
        "\n",
        "####  Tension and compression\n",
        "\n",
        "For the case of uniaxial tension and compression, we stretch the specimen in one direction,\n",
        "$F_{11} = \\lambda_1 = \\lambda$.\n",
        "For an isotropic, perfectly incompressible material with\n",
        "$I_3 = \\lambda_1^2  \\lambda_2^2  \\lambda_3^2 = 1$,\n",
        "the stretches orthogonal to the loading direction are identical and equal to the square root of the stretch,\n",
        "$F_{22} = \\lambda_2 = \\lambda^{-1/2}$ and\n",
        "$F_{33} = \\lambda_3 = \\lambda^{-1/2}$.\n",
        "From the resulting deformation gradient,\n",
        "$F= {\\rm{diag}} \\, \\{ \\; \\lambda, \\lambda^{-1/2}, \\lambda^{-1/2} \\,\\}$,\n",
        "we calculate the first and second invariants and their derivatives,\n",
        "\n",
        "$$\n",
        "  I_1\n",
        "= \\lambda^2 + \\frac{2}{\\lambda}\n",
        "  \\quad \\mbox{and} \\quad\n",
        "  I_2\n",
        "= 2\\lambda + \\frac{1}{\\lambda^2}\n",
        "  \\quad \\mbox{with} \\quad\n",
        "  \\frac{\\partial I_1}{\\partial  \\lambda}\n",
        "= 2 \\, \\left[\\lambda - \\frac{1}{\\lambda^2} \\right]\n",
        "  \\quad \\mbox{and} \\quad\n",
        "  \\frac{\\partial I_2}{\\partial  \\lambda}\n",
        "= 2 \\, \\left[1 - \\frac{1}{\\lambda^3}\\right] \\,,\n",
        "$$\n",
        "\n",
        "to evaluate the nominal uniaxial stress $P_{11}$\n",
        "using the general stress-stretch relationship for perfectly incompressible materials,\n",
        "$ P_{ii}\n",
        "= [{\\partial \\psi}/{\\partial I_1}] \\,\n",
        "  [{\\partial I_1} /{\\partial \\lambda_i}]\n",
        "+ [{\\partial \\psi}/{\\partial I_2}] \\,\n",
        "  [{\\partial I_2} /{\\partial \\lambda_i}]\n",
        "- [{1}/{\\lambda_i}] \\, p $,\n",
        "for $i = 1,2,3$.\n",
        "Here, $p$ denotes the hydrostatic pressure that we determine from the zero stress condition in the transverse directions, $P_{22} = 0$ and $P_{33} = 0$, as\n",
        "$ p\n",
        "= [{2}/{\\lambda}] \\;\n",
        "  {\\partial \\psi}/{\\partial I_1}\n",
        "+ [2\\lambda+{2}/{\\lambda^2}] \\,\n",
        "  {\\partial \\psi}/{\\partial I_2}$.\n",
        "This results in the following explicit uniaxial stress-stretch relation for perfectly incompressible, isotropic materials,\n",
        "\n",
        "$$\n",
        "  P_{11}\n",
        "= 2 \\,\n",
        "  \\left[\n",
        "  \\frac{\\partial \\psi}{\\partial I_1}\n",
        "+ \\frac{1}{\\lambda}\n",
        "  \\frac{\\partial \\psi}{\\partial I_2}\n",
        "  \\right]\n",
        "  \\left[\n",
        "  \\lambda - \\frac{1}{\\lambda^2}\n",
        "  \\right]\\,.\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUj9Kf5y3vAQ"
      },
      "outputs": [],
      "source": [
        "def Stress_calc_TC(inputs):\n",
        "    (dPsidI1, dPsidI2, Stretch) = inputs\n",
        "    one = tf.constant(1.0,dtype='float32')\n",
        "    two = tf.constant(2.0,dtype='float32')\n",
        "    minus  = two * (dPsidI1 *  one/ K.square(Stretch)  + dPsidI2 * one/K.pow(Stretch,3))\n",
        "    stress = two * (dPsidI1 *  Stretch + dPsidI2 * one) - minus\n",
        "\n",
        "    return stress"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY2kbH8d357e"
      },
      "source": [
        "####  Shear\n",
        "\n",
        "For the case of simple shear, we shear the specimen in one direction, $F_{12} = \\gamma$.\n",
        "For an isotropic, perfectly incompressible material with\n",
        "$F_{11} = F_{22} = F_{33} = 1$,\n",
        "we calculate the first and second invariants and their derivatives,\n",
        "$$\n",
        "  I_1\n",
        "= 3 + \\gamma^2\n",
        "  \\quad \\mbox{and} \\quad\n",
        "  I_2\n",
        "= 3 + \\gamma^2\n",
        "  \\quad \\mbox{with} \\quad\n",
        "  \\frac{\\partial I_1}{\\partial  \\lambda}\n",
        "= 2 \\, \\gamma\n",
        "  \\quad \\mbox{and} \\quad\n",
        "  \\frac{\\partial I_2}{\\partial  \\lambda}\n",
        "= 2 \\, \\gamma \\,,\n",
        "$$\n",
        "to evalute the nominal shear stress $P_{12}$\n",
        "using the general stress-stretch relationship for perfectly incompressible materials.\n",
        "This results in the following explicit shear stress-strain relation for perfectly incompressible, isotropic materials,\n",
        "$$\n",
        "  P_{12}\n",
        "= 2\\,\n",
        "  \\left[\n",
        "  \\frac{\\partial \\psi}{\\partial I_1}\n",
        "+ \\frac{\\partial \\psi}{\\partial I_2}\n",
        "  \\right]\n",
        "  \\gamma\\,.\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVH0ZVdl5gUu"
      },
      "outputs": [],
      "source": [
        " # uniaxial\n",
        "def Stress_cal_uni_11(inputs):\n",
        "    (dPsidJ1,dJ1dF1,minus) = inputs\n",
        "    T1 = dPsidJ1*(dJ1dF1 - minus)\n",
        "    return T1\n",
        "\n",
        "def Stress_cal_uni_11_I1I2(inputs):\n",
        "    (dPsidJ1,dPsidJ2,dJ1dF1,minus1,dJ2dF1,minus2) = inputs\n",
        "    T1 = (dPsidJ1*(dJ1dF1 - minus1)+ dPsidJ2*(dJ2dF1 - minus2))\n",
        "    return T1\n",
        "\n",
        "    # biaxial\n",
        "def Stress_cal_bi_11(inputs):\n",
        "    (dPsidJ1,dJ1dF1,minus1) = inputs\n",
        "    two = tf.constant(2.0,dtype='float32')\n",
        "    one = tf.constant(1.0,dtype='float32')\n",
        "    T1 = (dPsidJ1*(dJ1dF1 - minus1))\n",
        "    return T1\n",
        "def Stress_cal_bi_22(inputs):\n",
        "    (dPsidJ2,dJ1dF2,minus1) = inputs\n",
        "    two = tf.constant(2.0,dtype='float32')\n",
        "    one = tf.constant(1.0,dtype='float32')\n",
        "    T2 = (dPsidJ2*(dJ1dF2 - minus1))\n",
        "    return T2\n",
        "\n",
        " # biaxial\n",
        "def Stress_cal_bi_11_I1I2(inputs):\n",
        "    (dPsidJ1,dPsidJ2,dJ1dF1,minus1,dJ2dF1,minus2) = inputs\n",
        "    two = tf.constant(2.0,dtype='float32')\n",
        "    one = tf.constant(1.0,dtype='float32')\n",
        "    T1 = (dPsidJ1*(dJ1dF1 - minus1)+ dPsidJ2*(dJ2dF1 - minus2))\n",
        "    return T1\n",
        "def Stress_cal_bi_22_I1I2(inputs):\n",
        "    (dPsidJ1,dPsidJ2,dJ1dF2,minus1,dJ2dF2,minus2) = inputs\n",
        "    two = tf.constant(2.0,dtype='float32')\n",
        "    one = tf.constant(1.0,dtype='float32')\n",
        "    T2= (dPsidJ1*(dJ1dF2 - minus1) + dPsidJ2*(dJ2dF2 - minus2))\n",
        "    return T2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTwDkRFm4BWf"
      },
      "source": [
        "Finally, we can define seperate stress models for tension/compression, shear and a combination of all loading states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLlSaN-P4EHU"
      },
      "outputs": [],
      "source": [
        "# Gradient function\n",
        "## automatic gradients\n",
        "def myGradient(a, b):\n",
        "    der = tf.gradients(a, b, unconnected_gradients='zero')\n",
        "    return der[0]\n",
        "# Define H-layer\n",
        "class H_Layer_generalized_combi(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, nameU, setAl, init):\n",
        "        super(H_Layer_generalized_combi, self).__init__()\n",
        "        self.nameU = nameU\n",
        "        self.setAl = setAl\n",
        "        self.init =  init\n",
        "\n",
        "        self.alpha =  tf.Variable(initial_value=self.init, name=self.nameU, constraint=keras.constraints.NonNeg(), dtype=tf.float32, trainable=self.setAl)\n",
        "        #self.alpha =  tf.Variable(initial_value=self.init, name=self.nameU, constraint=keras.constraints.NonNeg(), dtype=tf.float32, trainable=False)\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "\n",
        "        return config\n",
        "\n",
        "    def call(self, lam):\n",
        "\n",
        "        one_five = tf.constant(1.502,dtype='float32')\n",
        "        two = tf.constant(2.0,dtype='float32')\n",
        "        four = tf.constant(4.0,dtype='float32')\n",
        "\n",
        "\n",
        "        lam1_bi=lam[0]\n",
        "        lam1_ps=lam[1]\n",
        "        lam_uni = lam[2]\n",
        "\n",
        "        alp = self.alpha\n",
        "\n",
        "\n",
        "        lam1=lam1_bi\n",
        "        lam2=lam1_bi\n",
        "        lam3= tf.math.pow(tf.math.multiply(lam1, lam2),-1.0)\n",
        "        J1_bi=tf.math.pow(lam1,alp) + tf.math.pow(lam2,alp) + tf.math.pow(lam3,alp)\n",
        "        dJ1dF1_bi=tf.math.multiply(alp,tf.math.pow(lam1,alp))\n",
        "        dJ1dF2_bi=tf.math.multiply(alp,tf.math.pow(lam2,alp))\n",
        "        minus_bi=tf.math.multiply(alp,tf.math.pow(lam3,alp))\n",
        "\n",
        "        lam1=lam1_ps\n",
        "        lam2=tf.ones_like(lam1)\n",
        "        lam3= tf.math.pow(tf.math.multiply(lam1, lam2),-1.0)\n",
        "        J1_ps=tf.math.pow(lam1,alp) + tf.math.pow(lam2,alp) + tf.math.pow(lam3,alp)\n",
        "        dJ1dF1_ps=tf.math.multiply(alp,tf.math.pow(lam1,alp))\n",
        "        dJ1dF2_ps=tf.math.multiply(alp,tf.math.pow(lam2,alp))\n",
        "        minus_ps=tf.math.multiply(alp,tf.math.pow(lam3,alp))\n",
        "\n",
        "        lam1=lam_uni\n",
        "        lam2=tf.math.pow(lam_uni,-0.5)\n",
        "        lam3=lam2\n",
        "        J1_uni=tf.math.pow(lam1,alp) + tf.math.pow(lam2,alp) + tf.math.pow(lam3,alp)\n",
        "        dJ1dF1_uni=tf.math.multiply(alp,tf.math.pow(lam1,alp))\n",
        "        minus_uni=tf.math.multiply(alp,tf.math.pow(lam3,alp))\n",
        "\n",
        "        return [J1_bi, dJ1dF1_bi, dJ1dF2_bi,minus_bi,J1_ps,dJ1dF1_ps,dJ1dF2_ps,minus_ps,J1_uni,dJ1dF1_uni,minus_uni]\n",
        "\n",
        "# Define H-layer for negative alpha\n",
        "class H_Layer_generalized_combi_neg(keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, nameU, setAl, init):\n",
        "        super(H_Layer_generalized_combi_neg, self).__init__()\n",
        "        self.nameU = nameU\n",
        "        self.setAl = setAl\n",
        "        self.init =  init\n",
        "\n",
        "        self.alpha =  tf.Variable(initial_value=self.init, name=self.nameU, constraint=keras.constraints.NonNeg(), dtype=tf.float32, trainable=self.setAl)\n",
        "        #self.alpha =  tf.Variable(initial_value=self.init, name=self.nameU, constraint=keras.constraints.NonNeg(), dtype=tf.float32, trainable=False)\n",
        "\n",
        "  def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "\n",
        "        return config\n",
        "\n",
        "  def call(self, lam):\n",
        "\n",
        "        one_five = tf.constant(1.502,dtype='float32')\n",
        "        two = tf.constant(2.0,dtype='float32')\n",
        "        four = tf.constant(4.0,dtype='float32')\n",
        "\n",
        "        lam1_bi=lam[0]\n",
        "        lam1_ps=lam[1]\n",
        "        lam_uni = lam[2]\n",
        "\n",
        "        alp = -self.alpha\n",
        "\n",
        "\n",
        "        lam1=lam1_bi\n",
        "        lam2=lam1_bi\n",
        "        lam3= tf.math.pow(tf.math.multiply(lam1, lam2),-1.0)\n",
        "        J1_bi=tf.math.pow(lam1,alp) + tf.math.pow(lam2,alp) + tf.math.pow(lam3,alp)\n",
        "        dJ1dF1_bi=tf.math.multiply(alp,tf.math.pow(lam1,alp))\n",
        "        dJ1dF2_bi=tf.math.multiply(alp,tf.math.pow(lam2,alp))\n",
        "        minus_bi=tf.math.multiply(alp,tf.math.pow(lam3,alp))\n",
        "\n",
        "        lam1=lam1_ps\n",
        "        lam2=tf.ones_like(lam1)\n",
        "        lam3= tf.math.pow(tf.math.multiply(lam1, lam2),-1.0)\n",
        "        J1_ps=tf.math.pow(lam1,alp) + tf.math.pow(lam2,alp) + tf.math.pow(lam3,alp)\n",
        "        dJ1dF1_ps=tf.math.multiply(alp,tf.math.pow(lam1,alp))\n",
        "        dJ1dF2_ps=tf.math.multiply(alp,tf.math.pow(lam2,alp))\n",
        "        minus_ps=tf.math.multiply(alp,tf.math.pow(lam3,alp))\n",
        "\n",
        "        lam1=lam_uni\n",
        "        lam2=tf.math.pow(lam_uni,-0.5)\n",
        "        lam3=lam2\n",
        "        J1_uni=tf.math.pow(lam1,alp) + tf.math.pow(lam2,alp) + tf.math.pow(lam3,alp)\n",
        "        dJ1dF1_uni=tf.math.multiply(alp,tf.math.pow(lam1,alp))\n",
        "        minus_uni=tf.math.multiply(alp,tf.math.pow(lam3,alp))\n",
        "\n",
        "\n",
        "        return [J1_bi, dJ1dF1_bi, dJ1dF2_bi,minus_bi,J1_ps,dJ1dF1_ps,dJ1dF2_ps,minus_ps,J1_uni,dJ1dF1_uni,minus_uni]\n",
        "\n",
        "def modelArchitecture(Psi_model):\n",
        "    # Stretch and Gamma as input\n",
        "    Stretch1_bi = keras.layers.Input(shape = (1,),\n",
        "                                  name = 'Stretch1_bi')\n",
        "    Stretch1_ps = keras.layers.Input(shape = (1,),\n",
        "                                  name = 'Stretch1_ps')\n",
        "    Stretch = keras.layers.Input(shape = (1,),\n",
        "                                  name = 'Stretch')\n",
        "\n",
        "    J1_bi, dJ1dF1_bi, dJ1dF2_bi,minus_bi,J1_ps,dJ1dF1_ps,dJ1dF2_ps,minus_ps,J1_uni,dJ1dF1_uni,minus_uni = H_Layer_generalized_combi('alpha1',True, 1.7)([Stretch1_bi,Stretch1_ps,Stretch])\n",
        "    J2_bi, dJ2dF1_bi, dJ2dF2_bi,minus_bi2,J2_ps,dJ2dF1_ps,dJ2dF2_ps,minus_ps2,J2_uni,dJ2dF1_uni,minus_uni2 = H_Layer_generalized_combi_neg('alpha2',True, 0.1)([Stretch1_bi,Stretch1_ps,Stretch])\n",
        "\n",
        "\n",
        "    # specific Invariants PS\n",
        "\n",
        "    I1_bi = keras.layers.Lambda(lambda x: x)(J1_bi)\n",
        "    I1_ps = keras.layers.Lambda(lambda x: x)(J1_ps)\n",
        "    I1_uni = keras.layers.Lambda(lambda x: x)(J1_uni)\n",
        "    I2_bi = keras.layers.Lambda(lambda x: x)(J2_bi)\n",
        "    I2_ps = keras.layers.Lambda(lambda x: x)(J2_ps)\n",
        "    I2_uni = keras.layers.Lambda(lambda x: x)(J2_uni)\n",
        "     #% load specific models\n",
        "\n",
        "    Psi_bi = Psi_model([I1_bi,I2_bi])\n",
        "    Psi_ps = Psi_model([I1_ps,I2_ps])\n",
        "    Psi_uni = Psi_model([I1_uni,I2_uni])\n",
        "\n",
        "    # derivatives\n",
        "    dWI1_bi  = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_bi, I1_bi])\n",
        "    dWI1_ps  = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_ps, I1_ps])\n",
        "    dWI1_uni  = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_uni, I1_uni])\n",
        "    dWI2_bi  = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_bi, I2_bi])\n",
        "    dWI2_ps  = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_ps, I2_ps])\n",
        "    dWI2_uni  = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_uni,I2_uni])\n",
        "    # Stress\n",
        "    Stress_11_bi = keras.layers.Lambda(function = Stress_cal_bi_11_I1I2,\n",
        "                                 name = 'Stress_11_bi')([dWI1_bi,dWI2_bi,dJ1dF1_bi,minus_bi,dJ2dF1_bi,minus_bi2])\n",
        "    Stress_11_ps = keras.layers.Lambda(function = Stress_cal_bi_11_I1I2,\n",
        "                                 name = 'Stress_11_ps')([dWI1_ps,dWI2_ps,dJ1dF1_ps,minus_ps,dJ2dF1_ps,minus_ps2])\n",
        "    Stress_11_uni = keras.layers.Lambda(function = Stress_cal_uni_11_I1I2,\n",
        "                                 name = 'Stress_uni_11')([dWI1_uni,dWI2_uni,dJ1dF1_uni,minus_uni,dJ2dF1_uni,minus_uni2])\n",
        "    # Define model for different load case\n",
        "    model_combi = keras.models.Model(inputs=[Stretch1_bi,Stretch1_ps,Stretch], outputs= [Stress_11_bi,Stress_11_ps,Stress_11_uni])\n",
        "\n",
        "    return model_combi, Psi_model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saYHO1e24JMm"
      },
      "source": [
        "### 4. Compile model\n",
        "\n",
        "The compiler definition comprises the loss function definition (here a mean squared error metric), the optimizer (here an Adam optimizer) and the evaluation metric (also mean squared error).\n",
        "\n",
        "Moreover, we define model callbacks and the keras fit function. The latter obtains the information about which model we want to fit with which data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmCtDWke4J5Y"
      },
      "outputs": [],
      "source": [
        "# Optimization utilities\n",
        "def Compile_and_fit(model_given, input_train, output_train, epochs, path_checkpoint):\n",
        "\n",
        "    mse_loss = keras.losses.MeanSquaredError()\n",
        "    metrics  =[keras.metrics.MeanSquaredError()]\n",
        "    opti1    = tf.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    model_given.compile(loss=mse_loss,\n",
        "                  optimizer=opti1,\n",
        "                  metrics=metrics)\n",
        "\n",
        "    # if training loss starts to increase, stop training after 3000 additional epochs = \"patience\"\n",
        "    ## early stopping if loss increasing innstead of decreasing\n",
        "\n",
        "    es_callback = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0, patience=3000, restore_best_weights=True)\n",
        "\n",
        "    modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"loss\",\n",
        "    filepath=path_checkpoint,\n",
        "    verbose=0,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True, # save only the best weights across all epochs\n",
        "    )\n",
        "\n",
        "## model.fit - input/output pairs of data to train on\n",
        "## sample_weights is how much each exampe is weighted in the loss fct\n",
        "    history = model_given.fit(input_train,\n",
        "                        output_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=0.0,\n",
        "                        callbacks=[es_callback, modelckpt_callback], # save best weights if stop early or go through all epochs\n",
        "                        shuffle = True,\n",
        "                        verbose = 0 ) # verbose = 2 will print loss each epoch\n",
        "\n",
        "\n",
        "    return model_given, history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwHIjb4g4Pni"
      },
      "source": [
        "### 5. Plot functions\n",
        "\n",
        "Here we define some plot functions to be used to plot the results later on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yT9Nfkj4QaD"
      },
      "outputs": [],
      "source": [
        "def plotLoss(axe, history):\n",
        "    axe.plot(history)\n",
        "    axe.set_yscale('log')\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOYoQXHk4XfL"
      },
      "outputs": [],
      "source": [
        "# plot the contribution of each term to the model stress prediction\n",
        "\n",
        "def color_map(ax, stretch, model, model_weights, Psi_model, cmaplist, terms, model_type, mode):\n",
        "    print(mode)\n",
        "    if mode=='c':\n",
        "      j=0\n",
        "    elif mode=='t':\n",
        "      j=1\n",
        "    elif mode=='s':\n",
        "      j=2\n",
        "    print(j)\n",
        "    stretch_triple=stretch\n",
        "    stretch=stretch[j]\n",
        "    predictions = np.zeros([stretch.shape[0], terms])\n",
        "    model_plot = copy.deepcopy(model_weights)  # deep copy model weights\n",
        "\n",
        "    for i in range(terms):\n",
        "        if model_type == 'Stretch':\n",
        "            model_plot = np.zeros_like(model_weights)  # wx1 all set to zero\n",
        "            model_plot[i] = model_weights[i]  # wx1[i] set to trained value\n",
        "        else:  # for architectures with multiple layers (VL, invariant)\n",
        "            model_plot[-1] = np.zeros_like(model_weights[-1])  # wx2 all set to zero\n",
        "            model_plot[-1][i] = model_weights[-1][i]  # wx2[i] set to trained value\n",
        "\n",
        "        Psi_model.set_weights(model_plot)\n",
        "        lower = np.sum(predictions, axis=1)\n",
        "        upper = lower + model.predict(stretch_triple, verbose=0)[j].flatten()\n",
        "        predictions[:, i] = model.predict(stretch_triple, verbose=0)[j].flatten()\n",
        "        ax.fill_between(stretch[:], lower.flatten(), upper.flatten(), lw=0, zorder=i + 1, color=cmaplist[i],\n",
        "                         label=i + 1)\n",
        "        ## plot each term's contribution\n",
        "\n",
        "        # if i == 0:  # one or two term models, get the correct color\n",
        "        #     ax.fill_between(stretch[:], lower.flatten(), upper.flatten(), lw=0, zorder=i + 1, color=cmaplist[0],\n",
        "        #                      label=i + 1)\n",
        "        # else:\n",
        "        #     ax.fill_between(stretch[:], lower.flatten(), upper.flatten(), lw=0, zorder=i + 1, color=cmaplist[7],\n",
        "        #                      label=i + 1)\n",
        "        ax.plot(stretch, upper, lw=0.4, zorder=34, color='k')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt5Fokjg4ags"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['xtick.major.pad'] = 14 # set plotting parameters\n",
        "plt.rcParams['ytick.major.pad'] = 14\n",
        "\n",
        "def generate_blue_shades(n=30):\n",
        "    \"\"\"\n",
        "    Generates a list of 'n' blue shades from dark to pale blue (near white),\n",
        "    passing through classical blue in the middle, and avoids violet tinting\n",
        "    by keeping red low and green moderate.\n",
        "    \"\"\"\n",
        "    blue_shades = []\n",
        "    for i in range(n):\n",
        "        t = i / (n - 1)\n",
        "\n",
        "        # Blue from 50 ‚Üí 255\n",
        "        b = int(50 + 205 * t)\n",
        "\n",
        "        if t <= 0.5:\n",
        "            # Dark to classical blue: keep R and G at 0\n",
        "            r = g = 0\n",
        "        else:\n",
        "            # Pale blue: increase green moderately, red minimally\n",
        "            fade = (t - 0.5) * 2  # 0 ‚Üí 1 over second half\n",
        "            g = int(fade * 200)   # green adds brightness\n",
        "            r = int(fade * 80)    # red is kept low to avoid violet\n",
        "\n",
        "        hex_color = f\"#{r:02X}{g:02X}{b:02X}\"\n",
        "        blue_shades.append(hex_color)\n",
        "    return blue_shades\n",
        "\n",
        "\n",
        "def generate_red_shades(n=30):\n",
        "    \"\"\"\n",
        "    Generates a list of 'n' red shades from dark red to light red (near white),\n",
        "    passing through a true, pure red in the middle.\n",
        "    Green and blue stay at 0 in the first half to preserve classical red.\n",
        "    \"\"\"\n",
        "    red_shades = []\n",
        "    for i in range(n):\n",
        "        # Position as fraction of the range\n",
        "        t = i / (n - 1)\n",
        "\n",
        "        # Red from 50 ‚Üí 255 uniformly\n",
        "        r = int(50 + 205 * t)\n",
        "\n",
        "        if t <= 0.5:\n",
        "            # Dark to pure red: green/blue = 0\n",
        "            g = b = 0\n",
        "        else:\n",
        "            # From pure red to pale red: increase G/B gradually to 230 max\n",
        "            fade = (t - 0.5) * 2  # scale from 0 ‚Üí 1 in second half\n",
        "            gb = int(fade * 230)\n",
        "            g = b = gb\n",
        "\n",
        "        hex_color = f\"#{r:02X}{g:02X}{b:02X}\"\n",
        "        red_shades.append(hex_color)\n",
        "    return red_shades\n",
        "\n",
        "# plot tension, compression, and shear data with color maps\n",
        "def plotMapAll(ax, Psi_model, model_weights, model_given, terms, lam_ut, P_ut, Region, path2saveResults, modelFit_mode, model_type):\n",
        "    blue_list = generate_blue_shades(30)\n",
        "    red_list = generate_red_shades(30)\n",
        "    cmaplist = [red_list[29],red_list[29],red_list[29],blue_list[29],blue_list[29],blue_list[29]]\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    fig, ax = plt.subplots(figsize=(12.5, 8.33))\n",
        "    ax.set_xlim(1.00,4.45)\n",
        "    ax.set_ylim( 0.0,10.915)\n",
        "    color_map(ax, lam_ut, model_given, model_weights, Psi_model, cmaplist, terms, model_type,'c')\n",
        "    ax.scatter(lam_ut[0], P_ut[0], s=800, zorder=103, lw=3, facecolors='w', edgecolors='k', clip_on=False)\n",
        "    plt.tight_layout(pad=2)\n",
        "    plt.savefig(path2saveResults + '/uc_' + 'Train'+ modelFit_mode + '_' + 'Region' + Region + '.pdf')\n",
        "    fig, ax = plt.subplots(figsize=(12.5, 8.33))\n",
        "    ax.set_xlim(1., 4.99)\n",
        "    ax.set_ylim(0., 9.082)\n",
        "    color_map(ax, lam_ut, model_given, model_weights, Psi_model, cmaplist, terms, model_type,'t')\n",
        "    ax.scatter(lam_ut[1], P_ut[1], s=800, zorder=103, lw=3, facecolors='w', edgecolors='k', clip_on=False)\n",
        "    plt.tight_layout(pad=2)\n",
        "    print(P_ut[1])\n",
        "    plt.savefig(path2saveResults + '/ut_' + 'Train'+ modelFit_mode + '_' + 'Region' + Region + '.pdf')\n",
        "    fig, ax = plt.subplots(figsize=(12.5, 8.33))\n",
        "    color_map(ax, lam_ut, model_given, model_weights, Psi_model, cmaplist, terms, model_type,'s')\n",
        "    ax.scatter(lam_ut[2], P_ut[2], s=800, zorder=103, lw=3, facecolors='w', edgecolors='k', clip_on=False)\n",
        "    plt.tight_layout(pad=2)\n",
        "    ax.set_xlim(1., 7.25)\n",
        "    ax.set_ylim(0.00, 32.58)\n",
        "    plt.savefig(path2saveResults + '/ss_' + 'Train'+ modelFit_mode + '_' + 'Region' + Region + '.pdf')\n",
        "    #plt.close();\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVRbZjO_4jBw"
      },
      "source": [
        "### 6. Model Training\n",
        "\n",
        "Parameters and definitions for the model training. Try changing the number of epochs and toggling between the invariant and principal-stretch-based model. Make sure to rename the model_type variable for each test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqeeGfNH4iNq"
      },
      "outputs": [],
      "source": [
        "train = True\n",
        "epochs = 30000# try ~5,000 epochs for a good fit\n",
        "batch_size = 12\n",
        "folder_name = 'rubber-bi-ps-uni-reg01-two-inv-trainable-with-ln' # name the folder for your results\n",
        "\n",
        "### Choose regularization type & penalty amount\n",
        "# Option: 'L1', 'L2'; for VL used L2=0.001, for Stretch no reg was used\n",
        "reg = 'L1'\n",
        "pen = 0.01  # Use 0 for no regularization\n",
        "\n",
        "### Choose which model type to build CANN architecture with\n",
        "# Options: 'Stretch', 'Invariant'\n",
        "# 'Stretch' is principal-stretch-based and contains stretches raised to fixed powers (range & number of terms can be adjusted)\n",
        "# 'Invariant' is invariant-based and contains I2, I2, I1^2, I2^2 and all with exp() and ln() activations\n",
        "model_type = 'Invariant'\n",
        "\n",
        "### Choose which loading modes to train with\n",
        "# Options: 'T', 'C', 'SS', 'TC_and_SS' (tension, compression, simple shear, tension/compression & simple shear)\n",
        "modelFit_mode_all = ['combi']\n",
        "\n",
        "### Choose which types of material to train with\n",
        "Region_all = ['rubber']\n",
        "################################################\n",
        "\n",
        "\n",
        "def makeDIR(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "\n",
        "filename = 'rubber-train-uni-bi-test-ps'\n",
        "path2saveResults_0 = path + 'results/'+filename+'/'+folder_name\n",
        "makeDIR(path2saveResults_0)\n",
        "Model_summary = path2saveResults_0 + '/Model_summary.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qYkzZBq_PG1r"
      },
      "outputs": [],
      "source": [
        "#  Training and validation loop\n",
        "count = 1\n",
        "for id1, Region in enumerate(Region_all): # loop through data\n",
        "\n",
        "    #R2_all_Regions = []\n",
        "    for id2, modelFit_mode in enumerate(modelFit_mode_all): # loop through model training modes\n",
        "\n",
        "        print(40*'=')\n",
        "        print(\"Comp {:d} / {:d}\".format(count, len(Region_all)*len(modelFit_mode_all)))\n",
        "        print(40*'=')\n",
        "        print(\"Region: \", Region ,\"| Fitting Mode: \", modelFit_mode)\n",
        "        print(40*'=')\n",
        "        count += 1\n",
        "\n",
        "        path2saveResults = os.path.join(path2saveResults_0,Region, modelFit_mode)\n",
        "        path2saveResults_check = os.path.join(path2saveResults,'Checkpoints')\n",
        "        makeDIR(path2saveResults)\n",
        "        makeDIR(path2saveResults_check)\n",
        "\n",
        "        # load experimantal data\n",
        "        lam1_bi,T1_bi,lam1_ps,T1_ps, lam_uni, T1_uni = getStressStrain(Region) # stress/stretch/shear pairs\n",
        "\n",
        "        # Model selection\n",
        "        if model_type == 'Invariant':\n",
        "            Psi_model, terms = StrainEnergyCANN_invariant(reg, pen) # build invariant-based model\n",
        "        elif model_type == 'Stretch':\n",
        "            Psi_model, terms = StrainEnergyCANN_stretch(reg, pen) # build principle-stretch-based model\n",
        "        model_combi, Psi_model = modelArchitecture(Psi_model) # build uniaxial and shear models\n",
        "\n",
        "\n",
        "        with open(Model_summary,'w') as fh:\n",
        "            # Pass the file handle in as a lambda function to make it callable\n",
        "            Psi_model.summary(line_length=80, print_fn=lambda x: fh.write(x + '\\n')) # summarize layers in architecture\n",
        "\n",
        "        #%%  Model training\n",
        "        model_given, input_train, output_train = traindata(modelFit_mode) # model type, input/output pairs\n",
        "\n",
        "\n",
        "        Save_path = path2saveResults + '/model.h5'\n",
        "        Save_weights = path2saveResults + '/weights'\n",
        "        path_checkpoint = path2saveResults_check + '/best_weights'\n",
        "        if train: # use compile/fit parameters to train specific model (UT, SS, both) with specific input/output pairs\n",
        "            model_given, history = Compile_and_fit(model_given, input_train, output_train, epochs, path_checkpoint)\n",
        "\n",
        "            model_given.load_weights(path_checkpoint, by_name=False, skip_mismatch=False) # load the weights saved in the path (the best ones)\n",
        "            tf.keras.models.save_model(Psi_model, Save_path, overwrite=True) # save the model\n",
        "            Psi_model.save_weights(Save_weights, overwrite=True) # save the weights\n",
        "\n",
        "            # Plot loss function\n",
        "            loss_history = history.history['loss']\n",
        "            fig, axe = plt.subplots(figsize=[6, 5])  # inches\n",
        "            plotLoss(axe, loss_history)\n",
        "            plt.savefig(path2saveResults+'/Plot_loss_'+Region+'_'+modelFit_mode+'.pdf')\n",
        "            plt.show()\n",
        "            #plt.close()\n",
        "\n",
        "        else: # if already trained, just load the saved weights\n",
        "            Psi_model.load_weights(Save_weights, by_name=False, skip_mismatch=False)\n",
        "\n",
        "\n",
        "        # Get CANN model response\n",
        "        #Stress_predict_combi = model_combi.predict([lam1_bi,lam1_ps,lam_uni], verbose=0)\n",
        "        #Stress_predict_SS = model_SS.predict(gamma_ss, verbose=0)\n",
        "\n",
        "        # Show weights\n",
        "        if model_type == 'Stretch':\n",
        "            weight_matrix = np.empty((terms, 1))\n",
        "            for i in range(terms):\n",
        "                value = Psi_model.get_weights()[i]\n",
        "                weight_matrix[i] = value\n",
        "            print(\"weight_matrix\")\n",
        "            print(*weight_matrix, sep=\"\\n\")\n",
        "\n",
        "        elif model_type == 'Invariant':\n",
        "            weight_matrix = np.empty((terms, 2))\n",
        "            for i in range(terms):\n",
        "                value = Psi_model.get_weights()[i][0][0]\n",
        "                weight_matrix[i, 0] = value\n",
        "                weight_matrix[:, 1] = Psi_model.get_layer('wx2').get_weights()[0].flatten()\n",
        "            print(\"weight_matrix\")\n",
        "            print(weight_matrix)\n",
        "\n",
        "        # Get the trained weights\n",
        "        model_weights_0 = Psi_model.get_weights()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M6czOgrrkrdk"
      },
      "outputs": [],
      "source": [
        "lam1_ps= dfs.iloc[4:18,6].dropna().astype(np.float64).values\n",
        "T1_ps = dfs.iloc[4:18,8].dropna().astype(np.float64).values*lam1_ps\n",
        "\n",
        "Stress_predict_combi = model_given.predict([lam1_bi,lam1_ps,lam_uni], verbose=0)\n",
        "\n",
        "R2_1 = r2_score(T1_bi,Stress_predict_combi[0])\n",
        "R2_2= r2_score(T1_ps, Stress_predict_combi[1])\n",
        "R2_uni = r2_score(T1_uni, Stress_predict_combi[2])\n",
        "\n",
        "\n",
        "print('R2_T1 = ', R2_1)\n",
        "print('R2_T2 = ', R2_2)\n",
        "print('R2_uni = ', R2_uni)\n",
        "\n",
        "a1=model_given.get_weights()[0]\n",
        "a2=model_given.get_weights()[1]\n",
        "\n",
        "#Save trained weights and R2 values to txt file\n",
        "Config = {\"Region\": Region, \"modelFit_mode\": modelFit_mode, 'model_type': model_type, 'Reg': reg, 'Penalty': pen, \"R2_1\": R2_1, \"R2_2\": R2_2, \"R2_uni\": R2_uni,\n",
        "                      \"alpha_pos\": a1.tolist(),\"alpha_neg\": a2.tolist(),\"weights\": weight_matrix.tolist()}\n",
        "json.dump(Config, open(path2saveResults + \"/Config_file.txt\", 'w'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cFMpdoiqRHMa"
      },
      "outputs": [],
      "source": [
        "# plot\n",
        "plotMapAll(ax,Psi_model, model_weights_0, model_given, terms, [lam1_bi,lam1_ps,lam_uni],[T1_bi,T1_ps,T1_uni], Region, path2saveResults, modelFit_mode, model_type)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}